[workspace]
name = "privox"
version = "1.0"
description = "Privox AI Assistant"
authors = ["Mark"]
channels = ["conda-forge", "pytorch", "nvidia"]
platforms = ["win-64", "osx-arm64", "osx-64"]

[tasks]
start = "python src/voice_input.py"
start-windowless = "pythonw src/voice_input.py"
build = "python build_app.py"

[system-requirements]
# CUDA is only needed/relevant for Windows/Linux
# We don't define it globally if we want to run on Mac

[dependencies]
python = ">=3.10,<3.13" 
pytorch = { version = "*", channel = "pytorch" }
torchaudio = { version = "*", channel = "pytorch" }
torchvision = { version = "*", channel = "pytorch" }
pip = "*"
cmake = "*"
ninja = "*"
numpy = "<2.0.0" 
pyinstaller = "*"
setuptools = "==69.5.1"

[target.win-64.dependencies]
pytorch-cuda = { version = "12.4.*", channel = "pytorch" }
cuda-toolkit = { version = "12.4.*", channel = "nvidia" }
cudnn = { version = "9.*", channel = "nvidia" }
llama-cpp-python = "*"
pywin32 = "*"

[target.osx-arm64.dependencies]
# No CUDA on Mac. 
# We don't strictly need llama-cpp-python if we use MLX

[target.osx-64.dependencies]
# Intel Macs (if supported) might still need llama-cpp-python or similar, but MLX is apple-silicon only
llama-cpp-python = "*"

[pypi-dependencies]
sounddevice = "*"
pynput = "*"
pystray = "*"
pillow = "*"
pyperclip = "*"
huggingface_hub = "*"
faster-whisper = "*"
funasr = "*"
modelscope = "*"
scipy = "*"
colorama = "*"
customtkinter = "*"
diskcache = "*"
pyside6 = "==6.8.1"

[target.osx-arm64.pypi-dependencies]
mlx-lm = "*"

